

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DINOv3 Keypoint Segmentation (DinoKPSEG) &mdash; annolid 1.5.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=9edc463e" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=73275c37"></script>
      <script src="_static/doctools.js?v=fd6eb6e6"></script>
      <script src="_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Agent Tools Developer Guide" href="agent_tools.html" />
    <link rel="prev" title="Image Editing (Local Diffusion / GGUF)" href="image_editing.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            annolid
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="guide.html">Annolid User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Install Annolid</a></li>
<li class="toctree-l1"><a class="reference internal" href="read_pdf_with_ai_voice.html">Read PDFs Aloud with AI Voice (Text-to-Speech)</a></li>
<li class="toctree-l1"><a class="reference internal" href="extract_frames.html">Extract Frames</a></li>
<li class="toctree-l1"><a class="reference internal" href="track_animals.html">Track animals and Auto labeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="track_animals.html#output-csv-format">Output CSV format</a></li>
<li class="toctree-l1"><a class="reference internal" href="track_animals.html#cutie-dino-body-part-tracker">Cutie + DINO Body-Part Tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="video_depth_anything.html">Video Depth Anything</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_editing.html">Image Editing (Local Diffusion / GGUF)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">DINOv3 Keypoint Segmentation (DinoKPSEG)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#native-labelme-training">Native LabelMe training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#native-coco-keypoints-training">Native COCO keypoints training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#relational-attention-head">Relational (Attention) Head</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#evaluation">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#coco-to-labelme-gui">COCO to LabelMe (GUI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-inference-gui">Running Inference (GUI)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="agent_tools.html">Agent Tools Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="yoloe_prompting.html">YOLOE-26 Prompting (Text / Visual / Prompt-free)</a></li>
<li class="toctree-l1"><a class="reference internal" href="keypoints_definitions.html">Config keypoint connection rules, events, and instances</a></li>
<li class="toctree-l1"><a class="reference internal" href="faqs.html">FAQs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">annolid</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">DINOv3 Keypoint Segmentation (DinoKPSEG)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/dino_kpseg.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="dinov3-keypoint-segmentation-dinokpseg">
<h1>DINOv3 Keypoint Segmentation (DinoKPSEG)<a class="headerlink" href="#dinov3-keypoint-segmentation-dinokpseg" title="Link to this heading"></a></h1>
<p>Annolid includes an experimental keypoint-centric segmentation model that:</p>
<ul class="simple">
<li><p>Extracts <strong>frozen DINOv3 dense features</strong> (ViT patch grid).</p></li>
<li><p>Trains a <strong>small convolutional head</strong> to predict per-keypoint masks.</p></li>
<li><p>Uses <strong>Gaussian keypoint heatmaps</strong> (or circular masks) as supervision.</p></li>
<li><p>Runs inference via the same prediction pipeline used for YOLO, saving results as LabelMe JSON.</p></li>
</ul>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Link to this heading"></a></h2>
<p>This trainer consumes either:</p>
<ul class="simple">
<li><p>A standard YOLO pose dataset (<code class="docutils literal notranslate"><span class="pre">data.yaml</span></code> with <code class="docutils literal notranslate"><span class="pre">kpt_shape</span></code> and labels in <code class="docutils literal notranslate"><span class="pre">labels/*.txt</span></code>), or</p></li>
<li><p>A native LabelMe dataset (per-image <code class="docutils literal notranslate"><span class="pre">*.json</span></code> next to images, with point/polygon shapes), or</p></li>
<li><p>A COCO keypoints dataset (<code class="docutils literal notranslate"><span class="pre">images</span></code> + <code class="docutils literal notranslate"><span class="pre">annotations/*.json</span></code>).</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--epochs<span class="w"> </span><span class="m">50</span>
</pre></div>
</div>
<section id="native-labelme-training">
<h3>Native LabelMe training<a class="headerlink" href="#native-labelme-training" title="Link to this heading"></a></h3>
<p>Create a small spec YAML that points to a directory (or JSONL index) of LabelMe JSON files:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">format</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">labelme</span>
<span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/path/to/dataset_root</span>
<span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">annotations/train</span><span class="w">   </span><span class="c1"># dir of LabelMe JSONs (images resolved via imagePath/sidecars)</span>
<span class="nt">val</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">annotations/val</span>
<span class="nt">kpt_shape</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">4</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">3</span><span class="p p-Indicator">]</span><span class="w">          </span><span class="c1"># K keypoints, dims (2 or 3)</span>
<span class="nt">keypoint_names</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">nose</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">leftear</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">rightear</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">tailbase</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Then train with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/labelme_spec.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data-format<span class="w"> </span>labelme<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--epochs<span class="w"> </span><span class="m">50</span>
</pre></div>
</div>
</section>
<section id="native-coco-keypoints-training">
<h3>Native COCO keypoints training<a class="headerlink" href="#native-coco-keypoints-training" title="Link to this heading"></a></h3>
<p>Create a COCO spec YAML:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">format</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">coco</span>
<span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/path/to/dataset_root</span>
<span class="nt">image_root</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">.</span><span class="w">                  </span><span class="c1"># optional; defaults to path</span>
<span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">annotations/train.json</span>
<span class="nt">val</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">annotations/val.json</span>
<span class="c1"># Optional overrides:</span>
<span class="c1"># kpt_shape: [27, 3]</span>
<span class="c1"># keypoint_names: [nose, left_ear, ...]</span>
</pre></div>
</div>
<p>Then train with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/coco_spec.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data-format<span class="w"> </span>coco<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--epochs<span class="w"> </span><span class="m">50</span>
</pre></div>
</div>
<p>Annolid will stage the COCO annotations into YOLO-pose labels automatically inside
the run directory and train with the same DinoKPSEG pipeline.</p>
<p>LabelMe conventions:</p>
<ul class="simple">
<li><p>Keypoints are <code class="docutils literal notranslate"><span class="pre">shape_type:</span> <span class="pre">point</span></code> with <code class="docutils literal notranslate"><span class="pre">label</span></code> matching an entry in <code class="docutils literal notranslate"><span class="pre">keypoint_names</span></code>.</p></li>
<li><p>Instances are grouped via <code class="docutils literal notranslate"><span class="pre">group_id</span></code> (all shapes with the same <code class="docutils literal notranslate"><span class="pre">group_id</span></code> belong together).</p></li>
<li><p>Polygons (<code class="docutils literal notranslate"><span class="pre">shape_type:</span> <span class="pre">polygon</span></code>) are optional; when present they are used to compute per-instance crops in <code class="docutils literal notranslate"><span class="pre">--instance-mode</span> <span class="pre">per_instance</span></code>.</p></li>
</ul>
<p>Defaults include Gaussian heatmaps, Dice loss, and a coordinate regression loss. Override as needed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--mask-type<span class="w"> </span>gaussian<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--heatmap-sigma<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--dice-loss-weight<span class="w"> </span><span class="m">0</span>.5<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--coord-loss-weight<span class="w"> </span><span class="m">0</span>.25<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--coord-loss-type<span class="w"> </span>smooth_l1
</pre></div>
</div>
<p>To train per instance (avoid multi-animal mask unions), use bounding-box crops:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--instance-mode<span class="w"> </span>per_instance<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--bbox-scale<span class="w"> </span><span class="m">1</span>.25
</pre></div>
</div>
<p>To fuse multiple DINO layers, pass a comma-separated list (features are concatenated):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--layers<span class="w"> </span>-2,-1
</pre></div>
</div>
</section>
<section id="relational-attention-head">
<h3>Relational (Attention) Head<a class="headerlink" href="#relational-attention-head" title="Link to this heading"></a></h3>
<p>For better left/right consistency on symmetric keypoints (e.g., ears), you can enable the attention head.
When <code class="docutils literal notranslate"><span class="pre">kpt_names</span></code> are available, DinoKPSEG will automatically treat asymmetric keypoints (e.g. <code class="docutils literal notranslate"><span class="pre">nose</span></code>, <code class="docutils literal notranslate"><span class="pre">head</span></code>, <code class="docutils literal notranslate"><span class="pre">tailbase</span></code>)
as orientation anchors and inject them into other keypoints via cross-attention.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--head-type<span class="w"> </span>attn<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--attn-heads<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--attn-layers<span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
<p>Optional symmetric-pair regularizers (requires <code class="docutils literal notranslate"><span class="pre">flip_idx</span></code> or inferable keypoint names):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--lr-pair-loss-weight<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--lr-pair-margin-px<span class="w"> </span><span class="m">8</span>
</pre></div>
</div>
<p>Optional left/right side-consistency (uses asymmetric anchors like <code class="docutils literal notranslate"><span class="pre">nose</span></code>/<code class="docutils literal notranslate"><span class="pre">tailbase</span></code> to define an axis):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--lr-side-loss-weight<span class="w"> </span><span class="m">0</span>.10<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--lr-side-loss-margin<span class="w"> </span><span class="m">0</span>.0
</pre></div>
</div>
<p>Outputs:</p>
<ul class="simple">
<li><p>A new run directory under <code class="docutils literal notranslate"><span class="pre">ANNOLID_RUNS_ROOT</span></code> (or <code class="docutils literal notranslate"><span class="pre">~/annolid_logs/runs</span></code>) such as:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">~/annolid_logs/runs/dino_kpseg/train/20260101_120000/weights/best.pt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">~/annolid_logs/runs/dino_kpseg/train/20260101_120000/weights/last.pt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">~/annolid_logs/runs/dino_kpseg/train/20260101_120000/args.yaml</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">~/annolid_logs/runs/dino_kpseg/train/20260101_120000/results.csv</span></code></p></li>
</ul>
</li>
</ul>
<p>To control where runs are written:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--runs-root<span class="w"> </span>/path/to/annolid_logs/runs<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--run-name<span class="w"> </span>experiment_01<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--epochs<span class="w"> </span><span class="m">50</span>
</pre></div>
</div>
</section>
</section>
<section id="evaluation">
<h2>Evaluation<a class="headerlink" href="#evaluation" title="Link to this heading"></a></h2>
<p>Run evaluation on the train/val split and report mean pixel error, PCK, and left/right swap rate:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.eval<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/YOLO_dataset/data.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--weights<span class="w"> </span>/path/to/dino_kpseg/weights/best.pt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--split<span class="w"> </span>val<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--thresholds<span class="w"> </span><span class="m">4</span>,8,16
</pre></div>
</div>
<p>For LabelMe datasets, pass the spec YAML and set <code class="docutils literal notranslate"><span class="pre">--data-format</span> <span class="pre">labelme</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>annolid.segmentation.dino_kpseg.eval<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data<span class="w"> </span>/path/to/labelme_spec.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--data-format<span class="w"> </span>labelme<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--weights<span class="w"> </span>/path/to/dino_kpseg/weights/best.pt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--split<span class="w"> </span>val
</pre></div>
</div>
<p>For COCO keypoints datasets, pass the COCO spec YAML and set <code class="docutils literal notranslate"><span class="pre">--data-format</span> <span class="pre">coco</span></code>.
Annolid will stage a temporary YOLO-pose view internally before evaluation.</p>
</section>
<section id="coco-to-labelme-gui">
<h2>COCO to LabelMe (GUI)<a class="headerlink" href="#coco-to-labelme-gui" title="Link to this heading"></a></h2>
<p>Use this when you have COCO keypoint annotations and want editable LabelMe JSON files.</p>
<ol class="arabic simple">
<li><p>Open Annolid.</p></li>
<li><p>Go to <strong>Convert → COCO to LabelMe</strong>.</p></li>
<li><p>Select your COCO annotations directory (for example <code class="docutils literal notranslate"><span class="pre">annotations/</span></code>).</p></li>
<li><p>Optionally select an image directory (you can cancel to use paths from the COCO file).</p></li>
<li><p>Select an output directory for the generated LabelMe dataset.</p></li>
</ol>
<p>What the converter writes:</p>
<ul class="simple">
<li><p>One image file plus one sidecar LabelMe JSON per COCO image (saved together).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">polygon</span></code> shapes from COCO polygon segmentations (when available).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rectangle</span></code> shapes from COCO bounding boxes (fallback when no polygons exist).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">point</span></code> shapes from COCO keypoints.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>Keypoints with non-visible flags (<code class="docutils literal notranslate"><span class="pre">v</span> <span class="pre">&lt;=</span> <span class="pre">0</span></code>) are skipped.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">group_id</span></code> is set from COCO annotation id, so polygon/box/keypoints from the same object stay linked.</p></li>
<li><p>If your COCO JSON is under <code class="docutils literal notranslate"><span class="pre">annotations/</span></code> and image files are under sibling <code class="docutils literal notranslate"><span class="pre">images/</span></code>,
Annolid auto-resolves those paths (you can still set images dir explicitly).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">imagePath</span></code> in output JSON is written as the local image filename next to the JSON sidecar.</p></li>
</ul>
</section>
<section id="running-inference-gui">
<h2>Running Inference (GUI)<a class="headerlink" href="#running-inference-gui" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Train the model (or point Annolid to a DinoKPSEG checkpoint).</p></li>
<li><p>In Annolid, select <strong>AI Model → DINOv3 Keypoint Segmentation</strong>.</p></li>
<li><p>Click <strong>Pred</strong> to run prediction.</p></li>
</ol>
<p>Optional instance-aware inference: draw rectangle prompts on the canvas (one per animal).
Annolid will run DinoKPSEG per box and keep keypoints grouped by instance.</p>
<p>The predictor saves:</p>
<ul class="simple">
<li><p>Point shapes for each keypoint.</p></li>
<li><p>A small polygon “circle mask” per keypoint (for quick visual segmentation).</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="image_editing.html" class="btn btn-neutral float-left" title="Image Editing (Local Diffusion / GGUF)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="agent_tools.html" class="btn btn-neutral float-right" title="Agent Tools Developer Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Chen Yang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>