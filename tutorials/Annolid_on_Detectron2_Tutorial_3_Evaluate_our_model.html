
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Annolid on Detectron2 Tutorial 3 : Evaluating the model &#8212; Annolid Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Annolid on Detectron2 Tutorial 4 : Running inference" href="Annolid_on_Detectron2_Tutorial_4_Running_inference.html" />
    <link rel="prev" title="Annolid on Detectron2 Tutorial 2 : Train a Model" href="Annolid_on_Detectron2_Tutorial_2_Train_a_Model.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../content/README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/cpl_logo.png" class="logo__image only-light" alt="Annolid Documentation - Home"/>
    <script>document.write(`<img src="../_static/cpl_logo.png" class="logo__image only-dark" alt="Annolid Documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../content/README.html">
                    Annolid Documentation
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../content/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/high_level_overview.html">High level overview</a></li>

<li class="toctree-l1"><a class="reference internal" href="../content/how_to_install.html">How to install</a></li>



<li class="toctree-l1"><a class="reference internal" href="../content/docker_container.html">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/gui_or_cli.html">GUI or CLI ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/extract_frames.html">Extract frames</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/labelling_images.html">How to label images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/save_labels.html">Save Labels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/create_coco.html">Create your COCO format dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/tips_and_tricks.html">Tips and tricks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Annolid_on_Detectron2_Tutorial_1_Introduction_to_Detectron2.html">Annolid on Detectron2 Tutorial 1 : Introduction to Detectron2</a></li>


<li class="toctree-l1"><a class="reference internal" href="Annolid_on_Detectron2_Tutorial_2_Train_a_Model.html">Annolid on Detectron2 Tutorial 2 : Train a Model</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Annolid on Detectron2 Tutorial 3 : Evaluating the model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Annolid_on_Detectron2_Tutorial_4_Running_inference.html">Annolid on Detectron2 Tutorial 4 : Running inference</a></li>

<li class="toctree-l1"><a class="reference internal" href="Annolid_on_Detectron2_Tutorial_full.html">Annolid on Detectron2 Tutorial</a></li>




<li class="toctree-l1"><a class="reference internal" href="Annolid_post_processing_distances.html">Calculate distances for a pair of instances in the same frame or the same instance across frames</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Annolid Zoo</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../content/annolid_zoo.html">Annolid ModelZoo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../content/contributing.html">New contributor guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/get_in_touch.html">Get in touch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/cite_annolid.html">Cite Annolid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content/work_based_on_annolid.html">Work based on annolid</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/healthonrails/annolid" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/healthonrails/annolid/issues/new?title=Issue%20on%20page%20%2Ftutorials/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tutorials/Annolid_on_Detectron2_Tutorial_3_Evaluate_our_model.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Annolid on Detectron2 Tutorial 3 : Evaluating the model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upload-a-labeled-dataset">Upload a labeled dataset.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-evaluation-using-the-trained-model">Inference &amp; evaluation using the trained model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-expand-on-how-to-interpret-ap">#TODO: expand on  how to interpret AP</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="annolid-on-detectron2-tutorial-3-evaluating-the-model">
<h1>Annolid on Detectron2 Tutorial 3 : Evaluating the model<a class="headerlink" href="#annolid-on-detectron2-tutorial-3-evaluating-the-model" title="Link to this heading">#</a></h1>
<p>This is modified from the official colab tutorial of detectron2. Here, we will</p>
<ul class="simple">
<li><p>Evaluate our previously trained model.</p></li>
</ul>
<p>You can make a copy of this tutorial by “File -&gt; Open in playground mode” and play with it yourself. <strong>DO NOT</strong> request access to this tutorial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Is running in colab or in jupyter-notebook</span>
<span class="k">try</span><span class="p">:</span>
  <span class="kn">import</span> <span class="nn">google.colab</span>
  <span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span><span class="p">:</span>
  <span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># install dependencies: </span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">pyyaml</span><span class="o">==</span><span class="m">5</span>.3
<span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">torchvision</span>
<span class="n">TORCH_VERSION</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">CUDA_VERSION</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;torch: &quot;</span><span class="p">,</span> <span class="n">TORCH_VERSION</span><span class="p">,</span> <span class="s2">&quot;; cuda: &quot;</span><span class="p">,</span> <span class="n">CUDA_VERSION</span><span class="p">)</span>
<span class="c1"># Install detectron2 that matches the above pytorch version</span>
<span class="c1"># See https://detectron2.readthedocs.io/tutorials/install.html for instructions</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>detectron2<span class="w"> </span>-f<span class="w"> </span>https://dl.fbaipublicfiles.com/detectron2/wheels/<span class="nv">$CUDA_VERSION</span>/torch<span class="nv">$TORCH_VERSION</span>/index.html
<span class="c1"># If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.</span>

<span class="c1"># exit(0)  # After installation, you may need to &quot;restart runtime&quot; in Colab. This line can also restart runtime</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyyaml==5.3 in /home/jeremy/anaconda3/lib/python3.9/site-packages (5.3)
torch:  1.10 ; cuda:  cu102
Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.10/index.html
Requirement already satisfied: detectron2 in /home/jeremy/anaconda3/lib/python3.9/site-packages (0.6+cu102)
Requirement already satisfied: fvcore&lt;0.1.6,&gt;=0.1.5 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (0.1.5.post20211023)
Requirement already satisfied: tqdm&gt;4.29.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (4.62.3)
Requirement already satisfied: Pillow&gt;=7.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (8.4.0)
Requirement already satisfied: iopath&lt;0.1.10,&gt;=0.1.7 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (0.1.9)
Requirement already satisfied: cloudpickle in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (2.0.0)
Requirement already satisfied: pydot in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (1.4.2)
Requirement already satisfied: yacs&gt;=0.1.8 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (0.1.8)
Requirement already satisfied: future in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (0.18.2)
Requirement already satisfied: omegaconf&gt;=2.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (2.1.1)
Requirement already satisfied: tensorboard in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (2.7.0)
Requirement already satisfied: hydra-core&gt;=1.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (1.1.1)
Requirement already satisfied: tabulate in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (0.8.9)
Requirement already satisfied: termcolor&gt;=1.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (1.1.0)
Requirement already satisfied: pycocotools&gt;=2.0.2 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (2.0.3)
Requirement already satisfied: matplotlib in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (3.4.3)
Requirement already satisfied: black==21.4b2 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from detectron2) (21.4b2)
Requirement already satisfied: toml&gt;=0.10.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from black==21.4b2-&gt;detectron2) (0.10.2)
Requirement already satisfied: click&gt;=7.1.2 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from black==21.4b2-&gt;detectron2) (8.0.3)
Requirement already satisfied: pathspec&lt;1,&gt;=0.8.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from black==21.4b2-&gt;detectron2) (0.9.0)
Requirement already satisfied: regex&gt;=2020.1.8 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from black==21.4b2-&gt;detectron2) (2021.8.3)
Requirement already satisfied: mypy-extensions&gt;=0.4.3 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from black==21.4b2-&gt;detectron2) (0.4.3)
Requirement already satisfied: appdirs in /home/jeremy/anaconda3/lib/python3.9/site-packages (from black==21.4b2-&gt;detectron2) (1.4.4)
Requirement already satisfied: pyyaml&gt;=5.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from fvcore&lt;0.1.6,&gt;=0.1.5-&gt;detectron2) (5.3)
Requirement already satisfied: numpy in /home/jeremy/anaconda3/lib/python3.9/site-packages (from fvcore&lt;0.1.6,&gt;=0.1.5-&gt;detectron2) (1.20.3)
Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from hydra-core&gt;=1.1-&gt;detectron2) (4.8)
Requirement already satisfied: portalocker in /home/jeremy/anaconda3/lib/python3.9/site-packages (from iopath&lt;0.1.10,&gt;=0.1.7-&gt;detectron2) (2.3.2)
Requirement already satisfied: setuptools&gt;=18.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from pycocotools&gt;=2.0.2-&gt;detectron2) (58.0.4)
Requirement already satisfied: cython&gt;=0.27.3 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from pycocotools&gt;=2.0.2-&gt;detectron2) (0.29.24)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from matplotlib-&gt;detectron2) (1.3.1)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from matplotlib-&gt;detectron2) (3.0.4)
Requirement already satisfied: python-dateutil&gt;=2.7 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from matplotlib-&gt;detectron2) (2.8.2)
Requirement already satisfied: cycler&gt;=0.10 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from matplotlib-&gt;detectron2) (0.10.0)
Requirement already satisfied: six in /home/jeremy/anaconda3/lib/python3.9/site-packages (from cycler&gt;=0.10-&gt;matplotlib-&gt;detectron2) (1.16.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (1.8.1)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (2.0.2)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (2.3.3)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (0.6.1)
Requirement already satisfied: protobuf&gt;=3.6.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (3.19.1)
Requirement already satisfied: grpcio&gt;=1.24.3 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (1.43.0)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (2.26.0)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (0.4.6)
Requirement already satisfied: wheel&gt;=0.26 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (0.37.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (3.3.6)
Requirement already satisfied: absl-py&gt;=0.4 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from tensorboard-&gt;detectron2) (1.0.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (4.8)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (0.2.8)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (4.2.4)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;detectron2) (1.3.0)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;detectron2) (4.8.1)
Requirement already satisfied: zipp&gt;=0.5 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;detectron2) (3.6.0)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (0.4.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (2.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (2021.10.8)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (1.26.7)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (3.2)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;detectron2) (3.1.1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import some common libraries</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
  <span class="kn">from</span> <span class="nn">google.colab.patches</span> <span class="kn">import</span> <span class="n">cv2_imshow</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup detectron2 logger</span>
<span class="kn">import</span> <span class="nn">detectron2</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.logger</span> <span class="kn">import</span> <span class="n">setup_logger</span>
<span class="n">setup_logger</span><span class="p">()</span>

<span class="c1"># import some common detectron2 utilities</span>
<span class="kn">from</span> <span class="nn">detectron2</span> <span class="kn">import</span> <span class="n">model_zoo</span>
<span class="kn">from</span> <span class="nn">detectron2.engine</span> <span class="kn">import</span> <span class="n">DefaultPredictor</span>
<span class="kn">from</span> <span class="nn">detectron2.config</span> <span class="kn">import</span> <span class="n">get_cfg</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">Visualizer</span>
<span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">MetadataCatalog</span><span class="p">,</span> <span class="n">DatasetCatalog</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># is there a gpu</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">GPU</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;gpu available&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">GPU</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;no gpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gpu available
</pre></div>
</div>
</div>
</div>
<section id="upload-a-labeled-dataset">
<h2>Upload a labeled dataset.<a class="headerlink" href="#upload-a-labeled-dataset" title="Link to this heading">#</a></h2>
<p>The following code is expecting the dataset in the COCO format to be in a <em><strong>.zip</strong></em> file. For example: <code class="docutils literal notranslate"><span class="pre">sample_dataset.zip</span></code> <br />
Note: please make sure there is no white space in your file path if you encounter file not found issues.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>gdown<span class="w"> </span>
<span class="o">!</span>gdown<span class="w"> </span>--id<span class="w"> </span>1fUXCLnoJ5SwXg54mj0NBKGzidsV8ALVR
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: gdown in /home/jeremy/anaconda3/lib/python3.9/site-packages (4.2.0)
Requirement already satisfied: six in /home/jeremy/anaconda3/lib/python3.9/site-packages (from gdown) (1.16.0)
Requirement already satisfied: beautifulsoup4 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from gdown) (4.10.0)
Requirement already satisfied: filelock in /home/jeremy/anaconda3/lib/python3.9/site-packages (from gdown) (3.3.1)
Requirement already satisfied: requests[socks] in /home/jeremy/anaconda3/lib/python3.9/site-packages (from gdown) (2.26.0)
Requirement already satisfied: tqdm in /home/jeremy/anaconda3/lib/python3.9/site-packages (from gdown) (4.62.3)
Requirement already satisfied: soupsieve&gt;1.2 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from beautifulsoup4-&gt;gdown) (2.2.1)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests[socks]-&gt;gdown) (2021.10.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests[socks]-&gt;gdown) (2.0.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests[socks]-&gt;gdown) (3.2)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests[socks]-&gt;gdown) (1.26.7)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /home/jeremy/anaconda3/lib/python3.9/site-packages (from requests[socks]-&gt;gdown) (1.7.1)
Downloading...
From: https://drive.google.com/uc?id=1fUXCLnoJ5SwXg54mj0NBKGzidsV8ALVR
To: /home/jeremy/Documents/annolid/book/tutorials/novelctrlk6_8_coco_dataset.zip
100%|██████████████████████████████████████| 10.3M/10.3M [00:00&lt;00:00, 97.5MB/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="s1">&#39;/content/novelctrlk6_8_coco_dataset.zip&#39;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="s1">&#39;novelctrlk6_8_coco_dataset.zip&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="o">!</span>unzip<span class="w"> </span><span class="nv">$dataset</span><span class="w"> </span>-d<span class="w"> </span>/content/
<span class="k">else</span><span class="p">:</span>
    <span class="c1">#TODO generalize this</span>
    <span class="o">!</span>unzip<span class="w"> </span>-o<span class="w"> </span><span class="nv">$dataset</span><span class="w"> </span>-d<span class="w"> </span>.
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Archive:  novelctrlk6_8_coco_dataset.zip
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001416_41.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004233_81.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004515_22.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000636_6.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006297_11.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006818_79.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006056_25.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006094_12.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004340_96.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000557_50.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000979_94.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005018_19.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001257_80.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004335_26.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004804_39.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006396_43.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006993_65.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000865_92.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003114_35.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001918_2.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004935_56.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006959_78.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005216_14.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003092_22.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001528_44.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003208_12.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004966_35.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004517_47.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004769_82.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004767_87.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000378_62.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006563_31.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001476_48.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004555_67.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003070_62.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005007_38.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003342_41.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002267_91.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002248_99.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000702_46.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003237_15.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002412_96.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00001322_73.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002328_97.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004312_85.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004443_46.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003783_81.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000779_3.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00002654_1.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004685_90.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004098_59.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006538_99.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006832_71.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00007024_26.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005772_51.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00006330_76.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00000871_10.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00003034_64.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00004539_89.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/JPEGImages/00005788_49.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/valid/annotations.json  
  inflating: ./novelctrlk6_8_coco_dataset/.DS_Store  
  inflating: ./__MACOSX/novelctrlk6_8_coco_dataset/._.DS_Store  
  inflating: ./novelctrlk6_8_coco_dataset/data.yaml  
  inflating: ./novelctrlk6_8_coco_dataset/train/.DS_Store  
  inflating: ./__MACOSX/novelctrlk6_8_coco_dataset/train/._.DS_Store  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001466_29.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006804_57.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00007044_50.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006232_55.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000759_28.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003680_32.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004441_88.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005090_94.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002476_27.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000965_42.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001652_55.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002000_18.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002333_0.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005752_39.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006670_0.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005763_18.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004469_75.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005566_43.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004336_74.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006574_88.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001922_1.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001795_5.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005755_34.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003576_54.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002647_78.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004295_47.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003667_56.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006131_85.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000311_77.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000879_40.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002991_7.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000757_5.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004628_68.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004348_33.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003269_66.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003224_49.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002628_21.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001838_25.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002825_40.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002247_29.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003100_30.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001922_57.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001320_92.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006299_63.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000952_60.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000842_70.jpg  
  inflating: ./__MACOSX/novelctrlk6_8_coco_dataset/train/JPEGImages/._00000842_70.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002295_32.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004117_59.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003976_44.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004032_20.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006212_69.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003134_31.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006169_98.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006830_36.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004570_24.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000735_23.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003905_42.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003012_37.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005456_95.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002456_9.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002433_90.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006715_97.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005597_15.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006319_53.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005025_83.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000530_64.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002362_63.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002311_72.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005068_37.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006353_11.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005056_91.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000970_34.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002577_24.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006601_16.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000652_65.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002639_95.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005953_8.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006000_27.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005700_89.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004672_51.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004062_19.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005246_28.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005154_53.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005584_93.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003834_80.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004711_6.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006038_20.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006373_2.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006470_84.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003956_16.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002625_79.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006270_45.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006521_86.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001999_45.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004081_4.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00000776_14.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002546_58.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001181_61.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002226_87.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001632_33.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006218_71.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00005400_9.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001299_86.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00002067_75.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006844_69.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001892_72.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001153_93.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001389_82.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001439_52.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006367_98.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004018_67.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004535_48.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006361_13.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003167_10.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00006832_66.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00004956_38.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00001980_61.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/JPEGImages/00003364_13.jpg  
  inflating: ./novelctrlk6_8_coco_dataset/train/annotations.json  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATASET_NAME</span> <span class="o">=</span> <span class="n">DATASET_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.zip&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.data.datasets</span> <span class="kn">import</span> <span class="n">register_coco_instances</span>
<span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">get_detection_dataset_dicts</span>
<span class="kn">from</span> <span class="nn">detectron2.data.datasets</span> <span class="kn">import</span>  <span class="n">builtin_meta</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">register_coco_instances</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_train&quot;</span><span class="p">,</span> <span class="p">{},</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_DIR</span><span class="si">}</span><span class="s2">/train/annotations.json&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_DIR</span><span class="si">}</span><span class="s2">/train/&quot;</span><span class="p">)</span>
<span class="n">register_coco_instances</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_valid&quot;</span><span class="p">,</span> <span class="p">{},</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_DIR</span><span class="si">}</span><span class="s2">/valid/annotations.json&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_DIR</span><span class="si">}</span><span class="s2">/valid/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_dataset_metadata</span> <span class="o">=</span> <span class="n">MetadataCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_train&quot;</span><span class="p">)</span>
<span class="n">_dataset_metadata</span><span class="o">.</span><span class="n">thing_colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">cc</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">cc</span> <span class="ow">in</span> <span class="n">builtin_meta</span><span class="o">.</span><span class="n">COCO_CATEGORIES</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_dicts</span> <span class="o">=</span> <span class="n">get_detection_dataset_dicts</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_train&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[01/24 14:31:51 d2.data.datasets.coco]: </span>Loaded 118 images in COCO format from novelctrlk6_8_coco_dataset/train/annotations.json
<span class=" -Color -Color-Green">[01/24 14:31:51 d2.data.build]: </span>Removed 0 images with no usable annotations. 118 images left.
<span class=" -Color -Color-Green">[01/24 14:31:51 d2.data.build]: </span>Distribution of instances among all 7 categories:
<span class=" -Color -Color-Cyan">|   category   | #instances   |  category  | #instances   |  category  | #instances   |</span>
<span class=" -Color -Color-Cyan">|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|</span>
<span class=" -Color -Color-Cyan">| _background_ | 0            |    nose    | 118          |  left_ear  | 118          |</span>
<span class=" -Color -Color-Cyan">|  right_ear   | 117          | tail_base  | 119          |   mouse    | 118          |</span>
<span class=" -Color -Color-Cyan">|   centroid   | 1            |            |              |            |              |</span>
<span class=" -Color -Color-Cyan">|    total     | 591          |            |              |            |              |</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">_dataset_metadata</span><span class="o">.</span><span class="n">thing_classes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">NUM_CLASSES</span><span class="si">}</span><span class="s2"> Number of classes in the dataset&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7 Number of classes in the dataset
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference-evaluation-using-the-trained-model">
<h2>Inference &amp; evaluation using the trained model<a class="headerlink" href="#inference-evaluation-using-the-trained-model" title="Link to this heading">#</a></h2>
<p>Now, let’s run inference with the trained model on the validation dataset. First, let’s create a predictor using the model we just trained:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">GPU</span><span class="p">:</span>
    <span class="o">!</span>nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mon Jan 24 14:31:51 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  N/A |
| 24%   34C    P8    20W / 250W |    429MiB /  7979MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1405      G   /usr/lib/xorg/Xorg                132MiB |
|    0   N/A  N/A     64929      G   /usr/lib/xorg/Xorg                261MiB |
|    0   N/A  N/A     65055      G   /usr/bin/gnome-shell                9MiB |
|    0   N/A  N/A     65407      G   ...AAAAAAAAA= --shared-files        8MiB |
+-----------------------------------------------------------------------------+
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.engine</span> <span class="kn">import</span> <span class="n">DefaultTrainer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">get_cfg</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">GPU</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">DEVICE</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span><span class="o">.</span><span class="n">merge_from_file</span><span class="p">(</span><span class="n">model_zoo</span><span class="o">.</span><span class="n">get_config_file</span><span class="p">(</span><span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;</span><span class="p">))</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATASETS</span><span class="o">.</span><span class="n">TRAIN</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_train&quot;</span><span class="p">,)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATASETS</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="p">()</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATALOADER</span><span class="o">.</span><span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1">#@param</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATALOADER</span><span class="o">.</span><span class="n">SAMPLER_TRAIN</span> <span class="o">=</span> <span class="s2">&quot;RepeatFactorTrainingSampler&quot;</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATALOADER</span><span class="o">.</span><span class="n">REPEAT_THRESHOLD</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS</span> <span class="o">=</span> <span class="n">model_zoo</span><span class="o">.</span><span class="n">get_checkpoint_url</span><span class="p">(</span><span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;</span><span class="p">)</span>  <span class="c1"># Let training initialize from model zoo</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">IMS_PER_BATCH</span> <span class="o">=</span>  <span class="mi">4</span> <span class="c1">#@param</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">BASE_LR</span> <span class="o">=</span> <span class="mf">0.0025</span> <span class="c1">#@param # pick a good LR</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">MAX_ITER</span> <span class="o">=</span> <span class="mi">3000</span> <span class="c1">#@param    # 300 iterations seems good enough for 100 frames dataset; you will need to train longer for a practical dataset</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">CHECKPOINT_PERIOD</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1">#@param </span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">BATCH_SIZE_PER_IMAGE</span> <span class="o">=</span> <span class="mi">32</span> <span class="c1">#@param   # faster, and good enough for this toy dataset (default: 512)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="n">NUM_CLASSES</span>  <span class="c1">#  (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">DefaultTrainer</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> 
<span class="n">trainer</span><span class="o">.</span><span class="n">resume_or_load</span><span class="p">(</span><span class="n">resume</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[01/24 14:31:54 d2.engine.defaults]: </span>Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=8, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[01/24 14:31:54 d2.data.datasets.coco]: </span>Loaded 118 images in COCO format from novelctrlk6_8_coco_dataset/train/annotations.json
<span class=" -Color -Color-Green">[01/24 14:31:54 d2.data.build]: </span>Removed 0 images with no usable annotations. 118 images left.
<span class=" -Color -Color-Green">[01/24 14:31:54 d2.data.dataset_mapper]: </span>[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style=&#39;choice&#39;), RandomFlip()]
<span class=" -Color -Color-Green">[01/24 14:31:54 d2.data.build]: </span>Using training sampler RepeatFactorTrainingSampler
<span class=" -Color -Color-Green">[01/24 14:31:54 d2.data.common]: </span>Serializing 118 elements to byte tensors and concatenating them all ...
<span class=" -Color -Color-Green">[01/24 14:31:54 d2.data.common]: </span>Serialized dataset takes 0.31 MiB
<span class=" -Color -Color-Red">WARNING</span> <span class=" -Color -Color-Green">[01/24 14:31:54 d2.solver.build]: </span>SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skip loading parameter &#39;roi_heads.box_predictor.cls_score.weight&#39; to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.box_predictor.cls_score.bias&#39; to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.box_predictor.bbox_pred.weight&#39; to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.box_predictor.bbox_pred.bias&#39; to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.mask_head.predictor.weight&#39; to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (7, 256, 1, 1) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.mask_head.predictor.bias&#39; to the model due to incompatible shapes: (80,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
<span class=" -Color -Color-Blue">roi_heads.box_predictor.bbox_pred.{bias, weight}</span>
<span class=" -Color -Color-Blue">roi_heads.box_predictor.cls_score.{bias, weight}</span>
<span class=" -Color -Color-Blue">roi_heads.mask_head.predictor.{bias, weight}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inference should use the config with parameters that are used in training</span>
<span class="c1"># cfg now already contains everything we&#39;ve set previously. </span>
<span class="c1"># We simply update the weights with the newly trained ones to perform inference:</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="s2">&quot;model_final.pth&quot;</span><span class="p">)</span>  <span class="c1"># path to the model we just trained</span>
<span class="c1"># set a custom testing threshold</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">SCORE_THRESH_TEST</span> <span class="o">=</span> <span class="mf">0.15</span>   <span class="c1">#@param {type: &quot;slider&quot;, min:0.0, max:1.0, step: 0.01}</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">DefaultPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we randomly select several samples to visualize the prediction results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">ColorMode</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_dicts</span> <span class="o">=</span> <span class="n">get_detection_dataset_dicts</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_valid&quot;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">dataset_dicts</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>    
    <span class="n">im</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;file_name&quot;</span><span class="p">])</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>  <span class="c1"># format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">im</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">metadata</span><span class="o">=</span><span class="n">_dataset_metadata</span><span class="p">,</span> 
                   <span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                   <span class="n">instance_mode</span><span class="o">=</span><span class="n">ColorMode</span><span class="o">.</span><span class="n">SEGMENTATION</span>   <span class="c1"># remove the colors of unsegmented pixels. This option is only available for segmentation models</span>
    <span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">draw_instance_predictions</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
        <span class="n">cv2_imshow</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_image</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_image</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[01/24 14:31:55 d2.data.datasets.coco]: </span>Loaded 60 images in COCO format from novelctrlk6_8_coco_dataset/valid/annotations.json
<span class=" -Color -Color-Green">[01/24 14:31:55 d2.data.build]: </span>Removed 0 images with no usable annotations. 60 images left.
<span class=" -Color -Color-Green">[01/24 14:31:55 d2.data.build]: </span>Distribution of instances among all 7 categories:
<span class=" -Color -Color-Cyan">|   category   | #instances   |  category  | #instances   |  category  | #instances   |</span>
<span class=" -Color -Color-Cyan">|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|</span>
<span class=" -Color -Color-Cyan">| _background_ | 0            |    nose    | 60           |  left_ear  | 60           |</span>
<span class=" -Color -Color-Cyan">|  right_ear   | 60           | tail_base  | 60           |   mouse    | 60           |</span>
<span class=" -Color -Color-Cyan">|   centroid   | 0            |            |              |            |              |</span>
<span class=" -Color -Color-Cyan">|    total     | 300          |            |              |            |              |</span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jeremy/anaconda3/envs/annolid-env/lib/python3.7/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the &#39;trunc&#39; function NOT &#39;floor&#39;). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode=&#39;trunc&#39;), or for actual floor division, use torch.div(a, b, rounding_mode=&#39;floor&#39;).
  max_size = (max_size + (stride - 1)) // stride * stride
/home/jeremy/anaconda3/envs/annolid-env/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
</pre></div>
</div>
<img alt="../_images/2bbefcb1654aaa64e79d0aa64cbe9c3c774f5d5e822ad60d90181fec50ff4f4d.png" src="../_images/2bbefcb1654aaa64e79d0aa64cbe9c3c774f5d5e822ad60d90181fec50ff4f4d.png" />
<img alt="../_images/7119040d52686cfad552883a621d571aae52d3968b1a6a22da6f968d62badab4.png" src="../_images/7119040d52686cfad552883a621d571aae52d3968b1a6a22da6f968d62badab4.png" />
<img alt="../_images/9c94e3b8fcd41e09c00d622f12e8dd4c37065c3f4c7a98df3e7a8baf698bc56b.png" src="../_images/9c94e3b8fcd41e09c00d622f12e8dd4c37065c3f4c7a98df3e7a8baf698bc56b.png" />
<img alt="../_images/884018e057f2580a533e2ff53c6a05fa5f3bc8fc04f9de52ca96336ce07d3475.png" src="../_images/884018e057f2580a533e2ff53c6a05fa5f3bc8fc04f9de52ca96336ce07d3475.png" />
</div>
</div>
<p>A more robust way to evaluate the model is to use a metric called Average Precision (AP) already implemented in the detectron2 package. If you want more precision on what the AP is, you can take a look <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score">here</a> and <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision">here</a>.</p>
<section id="todo-expand-on-how-to-interpret-ap">
<h3>#TODO: expand on  how to interpret AP<a class="headerlink" href="#todo-expand-on-how-to-interpret-ap" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.evaluation</span> <span class="kn">import</span> <span class="n">COCOEvaluator</span><span class="p">,</span> <span class="n">inference_on_dataset</span>
<span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">build_detection_test_loader</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">COCOEvaluator</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_valid&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;/content/eval_output/&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">COCOEvaluator</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_valid&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;eval_output/&quot;</span><span class="p">)</span>

<span class="n">val_loader</span> <span class="o">=</span> <span class="n">build_detection_test_loader</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DATASET_NAME</span><span class="si">}</span><span class="s2">_valid&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inference_on_dataset</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">evaluator</span><span class="p">))</span>
<span class="c1"># another equivalent way to evaluate the model is to use `trainer.test`</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">WARNING</span> <span class=" -Color -Color-Green">[01/24 14:31:56 d2.evaluation.coco_evaluation]: </span>COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.datasets.coco]: </span>Loaded 60 images in COCO format from novelctrlk6_8_coco_dataset/valid/annotations.json
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.dataset_mapper]: </span>[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style=&#39;choice&#39;)]
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.common]: </span>Serializing 60 elements to byte tensors and concatenating them all ...
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.data.common]: </span>Serialized dataset takes 0.15 MiB
<span class=" -Color -Color-Green">[01/24 14:31:56 d2.evaluation.evaluator]: </span>Start inference on 60 batches
<span class=" -Color -Color-Green">[01/24 14:31:57 d2.evaluation.evaluator]: </span>Inference done 11/60. Dataloading: 0.0008 s/iter. Inference: 0.0523 s/iter. Eval: 0.0180 s/iter. Total: 0.0712 s/iter. ETA=0:00:03
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.evaluator]: </span>Total inference time: 0:00:03.823960 (0.069527 s / iter per device, on 1 devices)
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.evaluator]: </span>Total inference pure compute time: 0:00:02 (0.051859 s / iter per device, on 1 devices)
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Preparing results for COCO format ...
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Saving results to eval_output/coco_instances_results.json
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Evaluate annotation type *bbox*
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.evaluate() finished in 0.02 seconds.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Accumulating evaluation results...
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.823
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.796
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.464
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.797
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |
|:------:|:------:|:------:|:------:|:------:|:-----:|
| 42.881 | 82.250 | 40.677 | 34.808 | 79.604 |  nan  |
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Some metrics cannot be computed and is shown as NaN.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Per-category bbox AP: 
| category     | AP     | category   | AP     | category   | AP     |
|:-------------|:-------|:-----------|:-------|:-----------|:-------|
| _background_ | nan    | nose       | 37.467 | left_ear   | 34.991 |
| right_ear    | 26.474 | tail_base  | 40.300 | mouse      | 75.175 |
| centroid     | nan    |            |        |            |        |
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Evaluate annotation type *segm*
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.evaluate() finished in 0.02 seconds.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>Accumulating evaluation results...
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.fast_eval_api]: </span>COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.689
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.712
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |
|:------:|:------:|:------:|:-----:|:------:|:-----:|
| 13.838 | 20.664 | 18.990 | 0.083 | 68.859 |  nan  |
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Some metrics cannot be computed and is shown as NaN.
<span class=" -Color -Color-Green">[01/24 14:32:01 d2.evaluation.coco_evaluation]: </span>Per-category segm AP: 
| category     | AP    | category   | AP    | category   | AP     |
|:-------------|:------|:-----------|:------|:-----------|:-------|
| _background_ | nan   | nose       | 0.000 | left_ear   | 0.000  |
| right_ear    | 0.025 | tail_base  | 0.307 | mouse      | 68.859 |
| centroid     | nan   |            |       |            |        |
OrderedDict([(&#39;bbox&#39;, {&#39;AP&#39;: 42.881449697137505, &#39;AP50&#39;: 82.2501044835862, &#39;AP75&#39;: 40.67677036400211, &#39;APs&#39;: 34.80797160883607, &#39;APm&#39;: 79.60396039603961, &#39;APl&#39;: nan, &#39;AP-_background_&#39;: nan, &#39;AP-nose&#39;: 37.46745432692759, &#39;AP-left_ear&#39;: 34.99076354765347, &#39;AP-right_ear&#39;: 26.474155569306223, &#39;AP-tail_base&#39;: 40.29951299145698, &#39;AP-mouse&#39;: 75.17536205034328, &#39;AP-centroid&#39;: nan}), (&#39;segm&#39;, {&#39;AP&#39;: 13.838099650346003, &#39;AP50&#39;: 20.663994970925664, &#39;AP75&#39;: 18.99009900990099, &#39;APs&#39;: 0.082999371365708, &#39;APm&#39;: 68.85850076626717, &#39;APl&#39;: nan, &#39;AP-_background_&#39;: nan, &#39;AP-nose&#39;: 0.0, &#39;AP-left_ear&#39;: 0.0, &#39;AP-right_ear&#39;: 0.024752475247524754, &#39;AP-tail_base&#39;: 0.3072450102153072, &#39;AP-mouse&#39;: 68.85850076626717, &#39;AP-centroid&#39;: nan})])
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "annolid-env"
        },
        kernelOptions: {
            name: "annolid-env",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'annolid-env'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Annolid_on_Detectron2_Tutorial_2_Train_a_Model.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Annolid on Detectron2 Tutorial 2 : Train a Model</p>
      </div>
    </a>
    <a class="right-next"
       href="Annolid_on_Detectron2_Tutorial_4_Running_inference.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Annolid on Detectron2 Tutorial 4 : Running inference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upload-a-labeled-dataset">Upload a labeled dataset.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-evaluation-using-the-trained-model">Inference &amp; evaluation using the trained model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-expand-on-how-to-interpret-ap">#TODO: expand on  how to interpret AP</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Chen Yang, Jeremy Forest, Matthew Einhorn, Thomas Cleland
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>