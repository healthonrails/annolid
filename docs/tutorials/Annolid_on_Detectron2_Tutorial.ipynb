{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlCWlQ2pTc88"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/healthonrails/annolid/blob/main/docs/tutorials/Annolid_on_Detectron2_Tutorial.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# Annolid on Detectron2 Tutorial\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "Welcome to Annolid on detectron2! This is modified from the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n",
        "* Run inference on images or videos, with an existing detectron2 model\n",
        "* Train a detectron2 model on a new dataset\n",
        "\n",
        "You can make a copy of this tutorial by \"File -> Open in playground mode\" and play with it yourself. __DO NOT__ request access to this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_FzH13EjseR"
      },
      "outputs": [],
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.3\n",
        "import torch, torchvision\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "if SystemExit != 0:\n",
        "  !pip install pycocotools>=2.0.1\n",
        "  !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "  import torch\n",
        "  assert torch.__version__.startswith(\"1.9\")    \n",
        "  !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3a1KdvbijJp"
      },
      "outputs": [],
      "source": [
        "# Is running in colab or in jupyter-notebook\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# import some common libraries\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import glob\n",
        "import numpy as np\n",
        "if IN_COLAB:\n",
        "  from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xed8MZ6gijJt"
      },
      "outputs": [],
      "source": [
        "# Setup detectron2 logger\n",
        "import torch\n",
        "import torchvision\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc-NcMJ-ijJv"
      },
      "outputs": [],
      "source": [
        "# is there a gpu\n",
        "if torch.cuda.is_available():\n",
        "    GPU = True\n",
        "    print('gpu available')\n",
        "else:\n",
        "    GPU = False\n",
        "    print('no gpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GXik0-s9zda"
      },
      "source": [
        "## Upload a labeled dataset.\n",
        "The following code is expecting the dataset in the COCO format to be in a ***.zip*** file. For example: ```sample_dataset.zip``` \\\n",
        "Note: please make sure the is no white space in your file path if you encounter file not found issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcWvszD899W4"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "else:\n",
        "    from ipywidgets import FileUpload\n",
        "    from IPython.display import display\n",
        "    !jupyter nbextension enable --py widgetsnbextension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daXprDuZijJy"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    uploaded = files.upload()\n",
        "else:\n",
        "    uploaded = FileUpload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zBV7ib8ijJz"
      },
      "source": [
        "Running the following cell should enable a clickable button to upload the .zip file. If no button appears, you might need to update / install nodeJS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufTsA1cPijJz"
      },
      "outputs": [],
      "source": [
        "display(uploaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJDnzMb9ijJ0"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    dataset =  list(uploaded.keys())[0]\n",
        "else:\n",
        "    dataset = list(uploaded.value.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gD2vEWtmZQ8"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !unzip $dataset -d /content/\"{dataset.replace('.zip','')}\"\n",
        "else:\n",
        "    #TODO generalize this\n",
        "    !unzip -o ../../sample_dataset/$dataset -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWfb29Cy9EdH"
      },
      "source": [
        "If your dataset has the same name as the file you uploaded, you do not need to manually input the name (just run the next cells). **Otherwise, you need to replace DATASET_NAME and DATASET_DIR with your own strings like `DATASET_NAME = \"NameOfMyDataset\"` and `DATASETDIR=\"NameOfMyDatasetDirectory\"`**. To do that, uncomment the commented out cell below and replace the strings with the appropriate names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21PxYqli7Y67"
      },
      "outputs": [],
      "source": [
        "DATASET_NAME = DATASET_DIR = f\"{dataset.replace('.zip','')}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHBg6H8cijJ2"
      },
      "outputs": [],
      "source": [
        "# DATASET_NAME = 'NameOfMyDataset' \n",
        "# DATASET_DIR = 'NameOfMyDatasetDirectory'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzRZngMi_ujx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "DATASET_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gak3KwomHghD"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a"
      },
      "source": [
        "# Run a pre-trained detectron2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKyUL4pngvE"
      },
      "source": [
        "First, we check a random selected image from our training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq9GY37ml1kr"
      },
      "outputs": [],
      "source": [
        "# select and display one random image from the training set\n",
        "img_file = random.choice(glob.glob(f\"{DATASET_DIR}/train/JPEGImages/*.*\"))\n",
        "im = cv2.imread(img_file)\n",
        "if IN_COLAB:\n",
        "    cv2_imshow(im)\n",
        "else:\n",
        "    plt.imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM1thbN-ntjI"
      },
      "source": [
        "Then, we create a Detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaihLCGHijJ4"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYAFJwQjijJ5"
      },
      "outputs": [],
      "source": [
        "if GPU:\n",
        "    pass\n",
        "else:\n",
        "    cfg.MODEL.DEVICE='cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUjkwRsOn1O0"
      },
      "outputs": [],
      "source": [
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1  # set threshold for this model\n",
        "# Find a model from Detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3KxiHO_0gb"
      },
      "outputs": [],
      "source": [
        "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM728kMR0ACL"
      },
      "outputs": [],
      "source": [
        "outputs['instances'].pred_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWnR6KMx2KK7"
      },
      "outputs": [],
      "source": [
        "MetadataCatalog.get(cfg.DATASETS.TRAIN[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IRGo8d0qkgR"
      },
      "outputs": [],
      "source": [
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "if IN_COLAB:\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "else:\n",
        "    plt.imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46VbBbUYijJ7"
      },
      "source": [
        "As we can see, the network doesn't detect what we want. That is expected as we have not fine-tuned the network with our custom dataset. We are going to do that in the next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in COCO format.\n",
        "\n",
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW"
      },
      "source": [
        "Register the custom dataset to Detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
        "Here, the dataset is in COCO format, therefore we register  into Detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIbAM2pv-urF"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import get_detection_dataset_dicts\n",
        "from detectron2.data.datasets import  builtin_meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb0Pr0C_ijJ8"
      },
      "outputs": [],
      "source": [
        "register_coco_instances(f\"{DATASET_NAME}_train\", {}, f\"{DATASET_DIR}/train/annotations.json\", f\"{DATASET_DIR}/train/\")\n",
        "register_coco_instances(f\"{DATASET_NAME}_valid\", {}, f\"{DATASET_DIR}/valid/annotations.json\", f\"{DATASET_DIR}/valid/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzKzTlwU_iHh"
      },
      "outputs": [],
      "source": [
        "dataset_dicts = get_detection_dataset_dicts([f\"{DATASET_NAME}_train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVJnolv9__eE"
      },
      "outputs": [],
      "source": [
        "_dataset_metadata = MetadataCatalog.get(f\"{DATASET_NAME}_train\")\n",
        "_dataset_metadata.thing_colors = [cc['color'] for cc in builtin_meta.COCO_CATEGORIES]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-dEBJmW447_"
      },
      "outputs": [],
      "source": [
        "_dataset_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llntrPobA2CM"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = len(_dataset_metadata.thing_classes)\n",
        "print(f\"{NUM_CLASSES} Number of classes in the dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of a randomly selected sample in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkNbUzUOLYf0"
      },
      "outputs": [],
      "source": [
        "for d in random.sample(dataset_dicts, 2):\n",
        "    if '\\\\' in d['file_name']:\n",
        "        d['file_name'] = d['file_name'].replace('\\\\','/')\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=_dataset_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    if IN_COLAB:\n",
        "        cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "    else:\n",
        "        plt.imshow(out.get_image()[:, :, ::-1])\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "## Train!\n",
        "\n",
        "Now, let's fine-tune the COCO-pretrained R50-FPN Mask R-CNN model with our custom dataset. It takes ~2 hours to train 3000 iterations on Colab's K80 GPU, or ~1.5 hours on a P100 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9vyoXX0xZcM",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "if GPU:\n",
        "    !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDrggVt7ijJ-"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYATMC8RijJ-"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-HlCD3eijJ_"
      },
      "outputs": [],
      "source": [
        "if GPU:\n",
        "    pass\n",
        "else:\n",
        "    cfg.MODEL.DEVICE='cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7unkuuiqLdqd"
      },
      "outputs": [],
      "source": [
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (f\"{DATASET_NAME}_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2 #@param\n",
        "cfg.DATALOADER.SAMPLER_TRAIN = \"RepeatFactorTrainingSampler\"\n",
        "cfg.DATALOADER.REPEAT_THRESHOLD = 0.3\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH =  8 #@param\n",
        "cfg.SOLVER.BASE_LR = 0.0025 #@param # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000 #@param    # 300 iterations seems good enough for 100 frames dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 1000 #@param \n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 #@param   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES  #  (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBXeH8UXFcqU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKs8eu8u8_mr",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "## Inference & evaluation using the trained model\n",
        "Now, let's run inference with the trained model on the validation dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "outputs": [],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. \n",
        "# We simply update the weights with the newly trained ones to perform inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "# set a custom testing threshold\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.15   #@param {type: \"slider\", min:0.0, max:1.0, step: 0.01}\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao8JdwZiijKA"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5LhISJqWXgM"
      },
      "outputs": [],
      "source": [
        "dataset_dicts = get_detection_dataset_dicts([f\"{DATASET_NAME}_valid\"])\n",
        "for d in random.sample(dataset_dicts, 4):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=_dataset_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.SEGMENTATION   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    if IN_COLAB:\n",
        "        cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "    else:\n",
        "        plt.imshow(out.get_image()[:, :, ::-1])\n",
        "        plt.show()\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kblA1IyFvWbT"
      },
      "source": [
        "A more robust way to evaluate the model is to use a metric called Average Precision (AP) already implemented in the detectron2 package. If you want more precision on what the AP is, you can take a look [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) and [here](https://en.wikipedia.org/w/index.php?title=Information_retrieval&oldid=793358396#Average_precision). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPMXoajNijKB"
      },
      "source": [
        "### #TODO: expand on  how to interpret AP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcYnHtY9ijKC"
      },
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9tECBQCvMv3"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    evaluator = COCOEvaluator(f\"{DATASET_NAME}_valid\", cfg, False, output_dir=\"/content/eval_output/\")\n",
        "else:\n",
        "    evaluator = COCOEvaluator(f\"{DATASET_NAME}_valid\", cfg, False, output_dir=\"eval_output/\")\n",
        "\n",
        "val_loader = build_detection_test_loader(cfg, f\"{DATASET_NAME}_valid\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFuPzChWzU6Q"
      },
      "source": [
        "# Let's test our newly trained mode on a new video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajsf88l3AAWU"
      },
      "source": [
        "## We download a video from a URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY5wFYbotW9i"
      },
      "outputs": [],
      "source": [
        "#e.g.\n",
        "#!wget https://hosting-website.com/your-video.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "606Pdue7BRP3"
      },
      "source": [
        "### Please change the VIDEO_INPUT to the path of your inference video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6AzoGTVijKE"
      },
      "outputs": [],
      "source": [
        "VIDEO_INPUT = '/content/video_top3.mp4'\n",
        "OUTPUT_DIR = \"/content/sample_dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckgZOsQJijKE"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn0LVJTWtLhJ"
      },
      "outputs": [],
      "source": [
        "video = cv2.VideoCapture(VIDEO_INPUT)\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "basename = os.path.basename(VIDEO_INPUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXLpO4_AtgGO"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "os.makedirs(OUTPUT_DIR,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14VKYjHr2gGg"
      },
      "outputs": [],
      "source": [
        "def _frame_from_video(video):\n",
        "  attempt = 0\n",
        "  for i in range(num_frames):\n",
        "      success, frame = video.read()\n",
        "      if success:\n",
        "          yield frame\n",
        "      else:\n",
        "          attempt += 1\n",
        "          if attempt >= 2000:\n",
        "              break\n",
        "          else:\n",
        "              video.set(cv2.CAP_PROP_POS_FRAMES, i+1)\n",
        "              print('Cannot read this frame:', i)\n",
        "              continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JHTT5XKIBsf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pycocotools.mask as mask_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIG71LHZPsgs"
      },
      "outputs": [],
      "source": [
        "class_names = _dataset_metadata.thing_classes\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Please change the skip_frames parameter if you want to skip some frames\n",
        "The default value is 1. If you set it to 10, only every 10th frame will be processed and other frames will be skipped"
      ],
      "metadata": {
        "id": "OqtVcaLWFiM7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYI_Cv-GBplZ"
      },
      "outputs": [],
      "source": [
        "frame_number = 0\n",
        "# select number of frames to skip e.g. 2 for every other frames \n",
        "# if skip_frames = 30, every 30th frame will be processed.\n",
        "# default 1 no skipping\n",
        "skip_frames = 1 #@param {type: \"slider\", min:0, max:30, step: 1}\n",
        "tracking_results = []\n",
        "VIS = True\n",
        "for frame in _frame_from_video(video):\n",
        "    if not frame_number % skip_frames == 0:\n",
        "        frame_number += 1\n",
        "        print(\"skipping frame number: \", frame_number)\n",
        "        continue\n",
        "    im = frame\n",
        "    outputs = predictor(im)\n",
        "    out_dict = {}  \n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "    num_instance = len(instances)\n",
        "    if num_instance == 0:\n",
        "        out_dict['frame_number'] = frame_number\n",
        "        out_dict['x1'] = None\n",
        "        out_dict['y1'] = None\n",
        "        out_dict['x2'] = None\n",
        "        out_dict['y2'] = None\n",
        "        out_dict['instance_name'] = None\n",
        "        out_dict['class_score'] = None\n",
        "        out_dict['segmentation'] = None\n",
        "        tracking_results.append(out_dict)\n",
        "        out_dict = {}\n",
        "    else:\n",
        "        boxes = instances.pred_boxes.tensor.numpy()\n",
        "        boxes = boxes.tolist()\n",
        "        scores = instances.scores.tolist()\n",
        "        classes = instances.pred_classes.tolist()\n",
        "\n",
        "        has_mask = instances.has(\"pred_masks\")\n",
        "\n",
        "        if has_mask:\n",
        "            rles =[\n",
        "                   mask_util.encode(np.array(mask[:,:,None], order=\"F\", dtype=\"uint8\"))[0]\n",
        "                   for mask in instances.pred_masks\n",
        "            ]\n",
        "            for rle in rles:\n",
        "              rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
        "\n",
        "        assert len(rles) == len(boxes)\n",
        "        for k in range(num_instance):\n",
        "            box = boxes[k]\n",
        "            out_dict['frame_number'] = frame_number\n",
        "            out_dict['x1'] = box[0]\n",
        "            out_dict['y1'] = box[1]\n",
        "            out_dict['x2'] = box[2]\n",
        "            out_dict['y2'] = box[3]\n",
        "            out_dict['instance_name'] = class_names[classes[k]]\n",
        "            out_dict['class_score'] = scores[k]\n",
        "            out_dict['segmentation'] = rles[k]\n",
        "            if frame_number % 1000 == 0:\n",
        "              print(f\"Frame number {frame_number}: {out_dict}\")\n",
        "            tracking_results.append(out_dict)\n",
        "            out_dict = {}\n",
        "        \n",
        "    # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    if VIS:\n",
        "        v = Visualizer(im[:, :, ::-1],\n",
        "                    metadata=_dataset_metadata, \n",
        "                    scale=0.5, \n",
        "                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "         )\n",
        "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "        out_image = out.get_image()[:, :, ::-1]\n",
        "        if frame_number % 1000 == 0:\n",
        "            if IN_COLAB:\n",
        "                cv2_imshow(out_image)\n",
        "            else:\n",
        "                plt.imshow(out_image)\n",
        "                plt.show()\n",
        "            #Trun off the visulization to save time after the first frame\n",
        "            VIS = False\n",
        "    frame_number += 1\n",
        "    print(f\"Processing frame number {frame_number}\")\n",
        "\n",
        "video.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGtm3KALxyqp"
      },
      "source": [
        "## All the tracking results will be saved to this Pandas dataframe. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W6dRQXoN85C"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(tracking_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIR1fe6zODRq"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgI8caT9-mlO"
      },
      "source": [
        "## Calculate the bbox center point x, y locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGBFdG8RIcZo"
      },
      "outputs": [],
      "source": [
        "cx = (df.x1 + df.x2)/2\n",
        "cy = (df.y1 + df.y2)/2\n",
        "df['cx'] = cx\n",
        "df['cy'] = cy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R2Xii899cob",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0NJtjZUsoQK"
      },
      "source": [
        "## Only save the top 1 prediction for each frame for each class\n",
        "Note: You can change the number to save top n predictions for each frame and an instance name. head(2), head(5), or head(n)\n",
        "To save all the predictions, please use `df.to_csv('my_tracking_results.csv')`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAJ5dU-EhDXP"
      },
      "outputs": [],
      "source": [
        "df_top = df.groupby(['frame_number','instance_name'],sort=False).head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27jn0z3_hTKS"
      },
      "outputs": [],
      "source": [
        "df_top.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A1KvDDe_K8P"
      },
      "source": [
        "## Visualize the center points with plotly scatter plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oY3tHTOTc-Z"
      },
      "outputs": [],
      "source": [
        "df_vis = df_top[df_top.instance_name != 'Text'][['frame_number','cx','cy','instance_name']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhxX1tpGI1LX"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "fig = px.scatter(df_vis, \n",
        "                 x=\"cx\",\n",
        "                 y=\"cy\", \n",
        "                 color=\"instance_name\",\n",
        "                 hover_data=['frame_number','cx','cy'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pfF0eecelCY"
      },
      "outputs": [],
      "source": [
        "from pathlib import  Path\n",
        "tracking_results_csv = f\"{Path(dataset).stem}_{Path(VIDEO_INPUT).stem}_{cfg.SOLVER.MAX_ITER}_iters_mask_rcnn_tracking_results_with_segmenation.csv\"\n",
        "df_top.to_csv(tracking_results_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlVKcxTW5tIa"
      },
      "source": [
        "## Download the tracking result CSV file to your local device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFpaGUfsPvJZ"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download(tracking_results_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u2dGs54Ctuo"
      },
      "source": [
        "## Save and download the trained model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSpX5Yr-Cyq-"
      },
      "outputs": [],
      "source": [
        "final_model_file = os.path.join(cfg.OUTPUT_DIR,'model_final.pth')\n",
        "files.download(final_model_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Annolid of Detectron2 Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}