

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Threshold based object segmenation &mdash; annolid v1.0.1 documentation</title>

  
      <script src="_static/jquery.js"></script>
      <script src="_static/underscore.js"></script>
      <script src="_static/doctools.js"></script>
      <script src="_static/language_data.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Config keypoint connection rules, events, and instances" href="keypoints_definitions.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            annolid
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="guide.html">Annolid User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Install Annolid</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html#install-detectron2-locally">Install Detectron2 locally</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html#install-detectron2-on-google-colab">Install Detectron2 on Google Colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html#optional-install-older-version-of-pytorch-for-yolact">Optional: Install older version of Pytorch for YOLACT</a></li>
<li class="toctree-l1"><a class="reference internal" href="extract_frames.html">Extract desired number of frames from a video based on optical flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="extract_frames.html#display-optical-flow-while-extracting-frames-with-show-flow-true">Display optical flow while extracting frames with <strong>–show_flow=True</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="extract_frames.html#save-all-the-frames-as-images">Save all the frames as images</a></li>
<li class="toctree-l1"><a class="reference internal" href="extract_frames.html#select-frames-randomly-by-reservoir-sampling">Select frames randomly by reservoir sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="extract_frames.html#extract-all-the-key-frames-from-a-video-used-by-the-compression-methods">Extract all the key frames from a video used by the compression methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="track_animals.html">Track animals and Auto labeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="track_animals.html#output-csv-format">Output CSV format</a></li>
<li class="toctree-l1"><a class="reference internal" href="keypoints_definitions.html">Config keypoint connection rules, events, and instances</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Threshold based object segmenation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#convert-wmv-format-to-mp4-format-using-ffmpeg">Convert WMV format to mp4 format using ffmpeg</a></li>
<li class="toctree-l1"><a class="reference internal" href="#save-the-extracted-frames-to-a-user-selected-output-directory">Save the extracted frames to a user selected output directory</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-track-multiple-objects-in-the-video">How to track multiple objects in the video?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-convert-coco-annonation-format-to-yolov5-format">How to convert coco annonation format to YOLOV5 format?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-train-a-custom-yolov5-model">How to train a custom YOLOV5 model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-track-objects-in-a-video-with-the-trained-model">How to track objects in a video with the trained model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-convert-labelme-labeled-dataset-to-coco-format">How to convert labelme labeled dataset to COCO format?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-train-a-yolact-model-with-a-custom-dataset">How to train a YOLACT model with a custom dataset?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-evaluate-a-video-based-on-a-trained-model">How to evaluate a video based on a trained model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#convert-the-tracking-results-csv-file-to-glitter2-csv-format">Convert the tracking results csv file to Glitter2 csv format</a></li>
<li class="toctree-l1"><a class="reference internal" href="#convert-the-keypoint-annotations-to-labelme-format">Convert the keypoint annotations to labelme format</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">annolid</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Threshold based object segmenation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/faqs.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="threshold-based-object-segmenation">
<h1>Threshold based object segmenation<a class="headerlink" href="#threshold-based-object-segmenation" title="Permalink to this headline">¶</a></h1>
<p>Added track bars for users to select HSV values to
segment ROIs in the provided video.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python annolid/main.py -v /path/to/my_video.mp4 --segmentation<span class="o">=</span>threshold
</pre></div>
</div>
<p><img alt="Threshold based segmentation" src="_images/threshold_based_segmentation.png" /></p>
</div>
<div class="section" id="convert-wmv-format-to-mp4-format-using-ffmpeg">
<h1>Convert WMV format to mp4 format using ffmpeg<a class="headerlink" href="#convert-wmv-format-to-mp4-format-using-ffmpeg" title="Permalink to this headline">¶</a></h1>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ffmpeg -i /path/to/my_video.wmv -c:a aac /path/to/my_video.mp4
</pre></div>
</div>
</div>
<div class="section" id="save-the-extracted-frames-to-a-user-selected-output-directory">
<h1>Save the extracted frames to a user selected output directory<a class="headerlink" href="#save-the-extracted-frames-to-a-user-selected-output-directory" title="Permalink to this headline">¶</a></h1>
<p>If not selected, it will save the extracted frames to a folder named with the video name without extension. For example, if the input video path is /path/to/my_video.mp4, the extracted frames will be saved in the folder /path/to/my_video.
The output directory is provided, the extracted frames will be saved /path/to/dest/my_video.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> annolid
python main.py -v /path/to/my_video.mp4 --extract_frames<span class="o">=</span><span class="m">20</span> --to /path/to/dest --algo<span class="o">=</span>uniform
</pre></div>
</div>
</div>
<div class="section" id="how-to-track-multiple-objects-in-the-video">
<h1>How to track multiple objects in the video?<a class="headerlink" href="#how-to-track-multiple-objects-in-the-video" title="Permalink to this headline">¶</a></h1>
<p>Currently, it just works for person class with pretrained YOLOV3 or YOLOV5 weights.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python annolid/main.py -v /path/to/my_video.mp4 --track<span class="o">=</span>YOLOV5
</pre></div>
</div>
</div>
<div class="section" id="how-to-convert-coco-annonation-format-to-yolov5-format">
<h1>How to convert coco annonation format to YOLOV5 format?<a class="headerlink" href="#how-to-convert-coco-annonation-format-to-yolov5-format" title="Permalink to this headline">¶</a></h1>
<p>The dataset is structured as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>my_yolo_dataset
├── images
│   ├── train
│   └── val
└── labels
    ├── train
    └── val
data.yaml
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">coco2yolo</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">my_coco_dataset</span><span class="o">/</span><span class="n">annotations</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">to</span> <span class="n">my_yolo_dataset</span> <span class="o">--</span><span class="n">dataset_type</span><span class="o">=</span><span class="n">val</span>
</pre></div>
</div>
</div>
<div class="section" id="how-to-train-a-custom-yolov5-model">
<h1>How to train a custom YOLOV5 model?<a class="headerlink" href="#how-to-train-a-custom-yolov5-model" title="Permalink to this headline">¶</a></h1>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> annolid/detector
cp -r my_yolo_dataset annolid/detector
<span class="nb">cd</span> yolov5
<span class="c1"># change nc (number of classes) in the models/yolo5x.yaml, default is 80</span>

python train.py --img <span class="m">640</span> --batch <span class="m">8</span> --epochs <span class="m">30</span> --data ../my_dataset_yolo/data.yaml --cfg ./models/yolov5x.yaml --weights yolov5x.pt --name yolov5x_my_model --cache
</pre></div>
</div>
</div>
<div class="section" id="how-to-track-objects-in-a-video-with-the-trained-model">
<h1>How to track objects in a video with the trained model?<a class="headerlink" href="#how-to-track-objects-in-a-video-with-the-trained-model" title="Permalink to this headline">¶</a></h1>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> annold
python main.py -v /path/to/my_video.mp4 --track<span class="o">=</span>YOLOV5 --weights<span class="o">=</span>detector/yolov5/runs/exp5_yolov5x_my_model/weights/best.pt
</pre></div>
</div>
</div>
<div class="section" id="how-to-convert-labelme-labeled-dataset-to-coco-format">
<h1>How to convert labelme labeled dataset to COCO format?<a class="headerlink" href="#how-to-convert-labelme-labeled-dataset-to-coco-format" title="Permalink to this headline">¶</a></h1>
<p>:warning: You might need to reinstall annolid because it requires <code class="docutils literal notranslate"><span class="pre">labelme</span></code>
and <code class="docutils literal notranslate"><span class="pre">pycocotools</span></code> now.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> annold
python main.py --labelme2coco<span class="o">=</span>/path/to/my_labeled_images --to /path/to/my_dataset_coco --labels<span class="o">=</span>/path/to/my_labels.txt --vis<span class="o">=</span>True
</pre></div>
</div>
<p>If vis is true, it will create an additional visualization folder.
The dataset is structured as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>../../datasets/mydataset_coco/
├── data.yaml
├── train
│   ├── annotations.json
│   └── JPEGImages
│       ├── 00000444.jpg
└── valid
    ├── annotations.json
    └── JPEGImages
        ├── 00000443.jpg
</pre></div>
</div>
<p><img alt="Visualization" src="_images/00002895_7.jpg" /></p>
<p>An example mask file</p>
<p><img alt="Masks" src="_images/00002895_7_mask.png" /></p>
</div>
<div class="section" id="how-to-train-a-yolact-model-with-a-custom-dataset">
<h1>How to train a YOLACT model with a custom dataset?<a class="headerlink" href="#how-to-train-a-yolact-model-with-a-custom-dataset" title="Permalink to this headline">¶</a></h1>
<p>Please create a dataset yaml file by using the
annolid/segementation/yolact/configs/mouse_a4_dataset.yaml as
an example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">annolild</span><span class="o">/</span><span class="n">segmentation</span><span class="o">/</span><span class="n">yolact</span>
<span class="n">python</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config</span><span class="o">=</span><span class="n">configs</span><span class="o">/</span><span class="n">my_custom_dataset</span><span class="o">.</span><span class="n">yaml</span>  <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span>
</pre></div>
</div>
</div>
<div class="section" id="how-to-evaluate-a-video-based-on-a-trained-model">
<h1>How to evaluate a video based on a trained model?<a class="headerlink" href="#how-to-evaluate-a-video-based-on-a-trained-model" title="Permalink to this headline">¶</a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">annolid</span><span class="o">/</span><span class="n">segmentation</span><span class="o">/</span><span class="n">yolact</span>
<span class="n">python</span> <span class="nb">eval</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">trained_model</span><span class="o">=</span><span class="n">weights</span><span class="o">/</span><span class="n">yolact_plus_resnet50_xxx_xxx_xxx_interrupt</span><span class="o">.</span><span class="n">pth</span> <span class="o">--</span><span class="n">score_threshold</span><span class="o">=</span><span class="mf">0.2</span> <span class="o">--</span><span class="n">top_k</span><span class="o">=</span><span class="mi">4</span> <span class="o">--</span><span class="n">video_multiframe</span><span class="o">=</span><span class="mi">1</span> <span class="o">--</span><span class="n">video</span><span class="o">=</span><span class="n">my_video</span><span class="o">.</span><span class="n">avi</span><span class="p">:</span><span class="n">my_result_video</span><span class="o">.</span><span class="n">mp4</span> <span class="o">--</span><span class="n">mot</span> <span class="o">--</span><span class="n">config</span><span class="o">=</span><span class="n">configs</span><span class="o">/</span><span class="n">my_custom_dataset</span><span class="o">.</span><span class="n">yaml</span>
</pre></div>
</div>
<p>Note: the output tracking CSV file and video will be saved to
the folder annolid/segmentation/results.</p>
</div>
<div class="section" id="convert-the-tracking-results-csv-file-to-glitter2-csv-format">
<h1>Convert the tracking results csv file to Glitter2 csv format<a class="headerlink" href="#convert-the-tracking-results-csv-file-to-glitter2-csv-format" title="Permalink to this headline">¶</a></h1>
<p>The result csv file named as tracking_results_nix.csv in the folder as provided in –to option.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">annolid</span><span class="o">/</span><span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">v</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">my_video</span><span class="o">.</span><span class="n">mkv</span> <span class="o">--</span><span class="n">tracks2glitter</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">tracking_results</span><span class="o">.</span><span class="n">csv</span> <span class="o">--</span><span class="n">to</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">results_dir</span><span class="o">/</span>
</pre></div>
</div>
</div>
<div class="section" id="convert-the-keypoint-annotations-to-labelme-format">
<h1>Convert the keypoint annotations to labelme format<a class="headerlink" href="#convert-the-keypoint-annotations-to-labelme-format" title="Permalink to this headline">¶</a></h1>
<p>e.g. <a class="reference external" href="https://github.com/DeepLabCut/Primer-MotionCapture/tree/master/mouse_m7s3">DeepLabCut Mouse dataset</a></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python annolid/main.py --keypoints2labelme /path/to/mouse_m7s3/  --keypoints /path/to/mouse_m7s3/CollectedData_xxxx.h5 
</pre></div>
</div>
<p><img alt="Example" src="_images/mouse_keypoints.png" /></p>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="keypoints_definitions.html" class="btn btn-neutral float-left" title="Config keypoint connection rules, events, and instances" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Chen Yang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>